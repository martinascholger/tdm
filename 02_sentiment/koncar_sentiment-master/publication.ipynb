{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Sentiment Analysis Tool Chain for 18<sup>th</sup> Century Periodicals\n",
    "\n",
    "*Philipp Koncar, Bernhard C. Geiger, Christina Glatz, Elisabeth Hobisch, Sanja Sarić, Martina Scholger, Yvonne Völkl, Denis Helic*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "### Sentiment Analysis\n",
    "Sentiment analysis is a common task in natural language processing (NLP) and aims for the automatic and computational identification of emotions, attitudes and opinions expressed in textual data (Pang et al. 2008). It is one of the most actively studied aspects of NLP and has enjoyed much attention since the early 2000s (Liu 2020), which was around the time the term sentiment analysis was arguably first mentioned (see Nasukawa and Yi 2003). However, the computational study of emotions and opinions contained in texts started earlier, and was not specifically referred to as sentiment analysis. For example, we saw the introduction of the *direction-based text interpretation model* (Hearst 1992), which assesses whether an author of a text is in favor of, neutral or opposed to a specific topic, already in the early 1990s. In another work, Hatzivassiloglou and McKeown (1997) proposed an algorithm that identifies words based on their positive or negative semantic orientation. This detection of polarity is also often referred to as sentiment analysis, while the classification on the basis of a systematized spectrum of human emotions is often called emotion analysis (Kim and Klinger 2019). Existing literature reported two main approaches to conduct sentiment analysis: (i) dictionary-based and (ii) classification-based (Liu and Zhang 2012). For the didactic purpose of this notebook, we focus on the dictionary-based approach, as it provides an easily comprehensible point to start with sentiment analysis and is more transparent to beginners. We point the interested reader to related works that studied sentiment through classification-based methods (e.g., Maas et al. 2011, Zehe et al. 2017, Zhang et al. 2018).\n",
    "\n",
    "Sentiment analysis is especially tailored to and widely used in the context of social media analysis and other web data such as product reviews (Pak and Paroubek 2010, Ortigosa et al. 2014, Hamilton et al. 2016). The application to literary (historical) texts, especially non-English texts, is still challenging due to the lack of dictionaries, methods and annotated corpora. Hence, a number of research projects in the context of computational literary studies are dedicated to the application of sentiment analysis to fill this gap. Examples are the investigation of German plays (Schmidt et al. 2018), the prediction of happy endings (Jannidis et al. 2017), the classification of genres (Kim et al. 2017; Henny-Krahmer 2018), or the investigation of Latin texts (Sprugnoli et al. 2020). In the project<sup>[1](#ftn1)</sup> *Distant Reading for Periodicals of the Enlightenment* (DiSpecs - [link to project website](http://gams.uni-graz.at/dispecs)), we analyze French, Italian and Spanish Spectator periodicals from the Digital Edition project *The Spectators in the International Context* (Ertler et al. 2011) in terms of their thematic, stylistic, and emotional orientation using different computational methods, including sentiment analysis. During the DiSpecs project, it became obvious that existing methods are only partly suitable for 18<sup>th</sup> century texts which comprise the Spectator Press. In particular, we encountered problems with shifts in word meanings and spellings between modern-day and 18<sup>th</sup> century languages. Therefore, we concluded that the development of appropriate methods for 18<sup>th</sup> century texts is necessary to further improve the quality of our analyses. With this work, we aim to demonstrate how to construct and apply sentiment dictionaries for 18<sup>th</sup> century French, Italian and Spanish. In addition to its didactic purpose, it shall serve as a stepping stone for the development of dedicated sentiment methods for non-contemporary languages.\n",
    "\n",
    "### The Spectators\n",
    "The corpus used for the sentiment analysis stems from the Digital Edition project *The Spectators in the International Context* (Ertler et al. 2011). The Spectator Press represents an 18<sup>th</sup> century literary-journalistic genre through which the ideas of Enlightenment were disseminated from England to the whole (Western) world, and which disappeared (almost entirely) by the end of the century. The first English periodicals were Richard Steele’s and Joseph Addison’s *The Tatler* (1709-11) and *The Spectator* (1711-12; 1714). They served as prototypes for the first French periodical *Le Misantrope* (1711-12), which should then become the model for hundreds of similar periodicals (Ertler 2012). Due to their high degree of dispersion, the Spectator periodicals are today generally considered a keystone in transfer of literary forms and social practices. Within them, new literary genres, such as the epistolary or the serialized novel were developed (Fischer 2014, 32; Hobisch 2017, 33-41; Fischer-Pernkopf et al. 2018, 30) and, for the first time in Modern history, problems and norms of individual lifestyle, social interaction, and gender relationship were publicly discussed addressing a social stratum that can be classified as (emerging bourgeois) middle class (i.e. separate from any ruling class) (Kühlmann 2012, 17-18). This means, the Spectator Press constitutes an important cultural heritage of the world not only because it influenced the discourse system of the Enlightenment, but also because it helped shape the social fabric of Western societies until today.\n",
    "\n",
    "Previous literary analysis (Ertler 2004; Hobisch 2017; Kay 1975; Lévrier 2007; Rau 1980) has shown that in the Spectator periodicals, the transmission of values, norms, and behavioral patterns takes place by an emotional implication of the audience. In other words, the authors usually address their readers directly (e.g. Dear reader!) and include them into the communication system of the periodicals (e.g. reader’s letters) (Fischer 2014). Furthermore, the authors present the new (bourgois) values, norms, and behavioral patterns by narrating stories from everyday life and depicting individual character portraits which are heavily loaded with positive and negative examples of how to be and how to behave in the enlightened society (Völkl 2022).\n",
    "\n",
    "### The DiSpecs Approach to Sentiment Analysis\n",
    "The Spectator periodicals transmit knowledge on values, norms, and behavioral patterns by putting an emphasis on the polarity concepts of virtue (socially accepted quality) and vice (socially unaccepted quality). Virtues, such as modesty, kindness or reason, and vices, such as hypocrisy, jealousy or vanity, are detailed through stories about positive and negative behavioural patterns and through depictions of positive and negative (character) traits, which are then hierarchised and assessed worthy or not worthy of emulation. In order to make the large number of virtues and vices comprehensible to the audience – which decidedly also includes women – they are incorporated into gender-stereotypical models, illustrating role models or warning examples. For example, the vicious characteristics of egoism and vanity are linked to the stereotypical models of the coquette or the fop and contrasted with virtuous models of women and men. All in all, the stereotypical (role) models with their manifold virtues and vices are packed into countless (exemplary) stories from everyday life and in (character) portraits, which are narratively woven into the plot (cf. Völkl 2022, 280-284). \n",
    "\n",
    "As a result, the French, Italian and Spanish Spectator periodicals (of which about 4.000 issues are in the Digital Edition) are imbued with sentiment-bearing terms. Sentiment analysis enables experts familiar with the historic context of the Spectators to investigate, for example, an author’s political orientation or the moral focus of a periodical by examining the dominant sentiment values in different parts of the periodicals. To answer such questions, one can explore the sentiment value of the terms used for the depiction of a (literary) character, such as Don Quijote, the dominant sentiment value in comments on new developments in women’s fashion or in the treatise about the Habsburg’s reign in Spain. While answering these questions is out of scope of this didactic exposition of sentiment analysis, they act as examples of potential applications of this method in literary and cultural studies.\n",
    "\n",
    "With the contribution presented here, we not only introduce new sentiment dictionaries for French, Italian and Spanish texts of the 18<sup>th</sup> century, but also build a freely and publicly available tool chain based on Jupyter Notebooks, enabling researchers to apply our dictionary creation process and sentiment analysis methods to their own material and projects. Our notebooks furthermore contain tutorial-style introductions to concepts such as word embeddings, k-nearest neighbor classification, and dictionary-based sentiment analysis. It is this didactic style that made us choose inherently interpretable and intuitively accessible methods, despite the fact that they may fall short of achieving state-of-the-art performance. Our notebooks can thus be both used in the classrooms of digital literary studies curricula, and as a skeleton for researchers in the field, who may exchange certain methodologies with more sophisticated ones.\n",
    "\n",
    "The proposed tool chain comprises two different parts: (i) the optional creation of sentiment dictionaries and (ii) the actual sentiment analysis. More precisely, the first part requires manual annotations of seed words from which we transfer sentiment to other words occurring in a similar context as seed words. To transfer sentiment, we train word embeddings and use a machine learning classification task. In doing so, we computationally extend the list of annotated words and avoid a more time-consuming and tedious manual annotation process. Note that this procedure is also adaptable to other languages (also contemporary languages). In the second part, we provide a collection of ready-to-use sentiment dictionaries (which we created with the first part of the tool chain) as well as methods to perform the actual sentiment analysis. The implemented methods range from listing basic descriptive statistics to various kinds of plots that allow for an easy interpretation of sentiment expressed in a given text corpus. Further, our methods analyze sentiment on a macro- and microscopic level, as they can not only be applied to a whole corpus providing a bigger picture of data, but also on a document level, for example, by highlighting words that convey sentiment in any given text.\n",
    "\n",
    "This repository contains all the data we used for creating sentiment dictionaries, including manually annotated seed words, pretrained word embedding models and other data resulting from intermediate steps. These can also be used in other contexts and NLP tasks and are not necessarily limited to sentiment analysis. As such, our tool chain serves as a foundation for further methods and approaches applicable to all projects focusing on the computational interpretation of texts.\n",
    "\n",
    "Before we continue, please import the necessary Python packages for the interactive examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import seaborn\n",
    "import re\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from IPython.display import display, HTML, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, please execute the following cell to download data (i.e., the Punkt tokenizer) provided by NLTK which is necessary for the examples presented in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\semlakm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[<span id=\"ftn1\">1</span>] A cooperation between the Institute for Interactive Systems and Data Science at Graz University of Technology, the Know-Center GmbH as well as the Centre for Information Modelling - Austrian Centre for Digital Humanities (ZIM-ACDH) and the Institute of Romance Studies, both at the University of Graz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Dictionaries for the 18<sup>th</sup> Century\n",
    "\n",
    "In this section, we describe the process of how we created sentiment dictionaries and provide examples for the underlying methods. Please proceed with the *Sentiment Analysis for the 18<sup>th</sup> Century* section if you want to use our ready-to-use dictionaries for French, Italian and Spanish of the 18<sup>th</sup> century.\n",
    "The Jupyter Notebooks, which can be easily used by everyone to create sentiment dictionaries for their own projects, can be found in the `code/dictionary_creation/` directory of this repository.\n",
    "\n",
    "The process for creating sentiment dictionaries comprises three major steps, each of them described in more detail in the sections below. Overall, we first need to generate a set of seed words which serves as a basis to automatically transfer sentiment to other words in the text corpus. For this expansion, we train word embeddings to capture the context of individual words and use them in a classification task to transfer sentiment of seed words to other words in similar contexts. Note that this process is suitable for a plethora of languages and is not limited to the 18<sup>th</sup> century languages. The following figure illustrates the whole dictionary creation pipeline:\n",
    "\n",
    "![Overview of the Dictionary Creation Pipeline](miscellaneous/dictionary_creation_overview.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Dictionaries 101\n",
    "\n",
    "Before we discuss the individual steps to create sentiment dictionaries, we want to give a short introduction of what sentiment dictionaries are and how they can be used for sentiment analysis.\n",
    "Assume we want to assess the sentiment on a sentence level and that we are given the following three sentences:\n",
    "\n",
    "**Sentence 1:** Today was a good day.<br>\n",
    "**Sentence 2:** I hate getting up early.<br>\n",
    "**Sentence 3:** This is both funny and sad at the same time.\n",
    "\n",
    "Further, we have a sentiment dictionary, which comprises a list of words, each associated with sentiment (e.g., positive or negative):\n",
    "\n",
    "| Word | Sentiment |\n",
    "| --- | --- |\n",
    "| good | positive |\n",
    "| bad | negative |\n",
    "| hate | negative |\n",
    "| funny | positive |\n",
    "| sad | negative |\n",
    "| happy | positive |\n",
    "\n",
    "We can then assess the sentiment of each sentence by considering whether the words contained in the dictionary occur in them.\n",
    "For that, let us define the sentiment *s* of a sentence as follows:\n",
    "\n",
    "![Sentiment Formula for the Introductory Example](miscellaneous/sentiment_formula_1.png)\n",
    "\n",
    "where $W_p$ is the number of positive words in a sentence and $W_n$ is the number of negative words in a sentence.\n",
    "Thus, the formula subtracts the number of words with a negative sentiment from the number of words with a positive sentiment.\n",
    "If the resulting value is negative, then we assume the sentiment of a sentence to be negative, whereas if the value is positive, we assume the sentiment of a sentence to be positive.\n",
    "This value is zero if the two numbers are equal or if there are no words from the dictionary in a sentence. In this case, we assume that the sentence has a neutral sentiment.\n",
    "\n",
    "For our three examples, this means that Sentence 1 has a positive sentiment, Sentence 2 a negative sentiment and Sentence 3 a neutral sentiment.\n",
    "To verify whether our assumption is true, we implement the example in Python. For that, we first create a list that contains the three example sentences from above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "example_sentences = [\n",
    "    \"Today was a good day.\",\n",
    "    \"I hate getting up early.\",\n",
    "    \"This is both funny and sad at the same time.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further, we need to create a dictionary that maps our words in the dictionary to a sentiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_dictionary = {\n",
    "    \"good\": \"positive\",\n",
    "    \"bad\": \"negative\",\n",
    "    \"hate\": \"negative\",\n",
    "    \"funny\": \"positive\",\n",
    "    \"sad\": \"negative\",\n",
    "    \"happy\": \"positive\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then define a function that takes one sentence as input and returns its computed sentiment following the formula and rules stated above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sentiment(sentence):\n",
    "    wpt = WordPunctTokenizer()\n",
    "    words_list = wpt.tokenize(sentence)\n",
    "    number_of_negative_words = 0\n",
    "    number_of_positive_words = 0\n",
    "    for word, sentiment in sentiment_dictionary.items():\n",
    "        if sentiment == \"negative\":\n",
    "            number_of_negative_words += words_list.count(word)\n",
    "        elif sentiment == \"positive\":\n",
    "            number_of_positive_words += words_list.count(word)\n",
    "    sentiment_score = number_of_positive_words - number_of_negative_words\n",
    "    if sentiment_score < 0:\n",
    "        computed_sentiment = \"negative\"\n",
    "    elif sentiment_score > 0:\n",
    "        computed_sentiment = \"positive\"\n",
    "    else:\n",
    "        computed_sentiment = \"neutral\"\n",
    "    return computed_sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then iterate through the list of sentences and print the sentiment for each of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment for 'Today was a good day.' is positive.\n",
      "The sentiment for 'I hate getting up early.' is negative.\n",
      "The sentiment for 'This is both funny and sad at the same time.' is neutral.\n"
     ]
    }
   ],
   "source": [
    "for sentence in example_sentences:\n",
    "    print(\"The sentiment for '{}' is {}.\".format(sentence, compute_sentiment(sentence)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can now observe, the verification of our previous assumptions through Python confirms that they were all correct.\n",
    "\n",
    "The example above highlights the advantages of dictionary-based sentiment analysis approaches: first, it is straightforward to conduct (as demonstrated above) and second, the produced results are transparent and easily interpretable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Selecting Seed Words\n",
    "\n",
    "Our sentiment dictionary creation depends on seed words for which the sentiment is known. Based on these seed words, we can automatically transfer sentiment to other words, allowing us to circumvent a more tedious and time-consuming annotation process. This step comprises three parts: First, we extract seed words from the text corpus. Second, we manually annotate them. Third, we select annotated seed words based on the agreement of multiple annotators.\n",
    "\n",
    "#### Extracting Frequent Words\n",
    "At first, we extract the 3,000 most frequent words from the entire text corpus (without removing stop words or conducting lemmatization). The number of extracted seed words depends on the corpus size. We decided for a compromise between the number of words and the associated efforts to annotate them.\n",
    "In this case, these 3,000 most frequent words account for 3.9% of unique French words (76,035 in total), 2.5% of unique Italian words (121,504 in total) and 3.6% of unique Spanish words (84,185 in total).\n",
    "Focusing on most frequent words allows us to achieve a good coverage as seed words that do not occur frequently in our texts are of no use in the subsequent classification task.\n",
    "The Jupyter Notebook for the extraction of seed words (see `code/dictionary_creation/1_seed_words/1_extraction.ipynb`) allows for additional settings, such as a maximum document frequency of words to extract.\n",
    "\n",
    "#### Annotating Frequent Words\n",
    "Once we extracted frequent words, three experts, who are familiar with the content and context of the French, Italian and Spanish Spectator periodicals, annotated the seed words.\n",
    "In particular, we instructed them to assign each of the extracted words to either of three sentiment classes: (i) positive, (ii) negative or (iii) neutral and to take into account the sociocultural circumstances of the 18<sup>th</sup> century.\n",
    "As a result, the annotators captured the sentiment of words with regard to their intended meaning.\n",
    "\n",
    "The provided Jupyter Notebook (see `code/dictionary_creation/1_seed_words/2_annotation.ipynb`) for the annotation of words includes a few simple code lines to generate *.csv* files which can then be opened and annotated in an arbitrary spreadsheet program (e.g., Microsoft Excel or LibreOffice Calc).\n",
    "Note that the annotated sentiment needs to be entered in the *sentiment* column of the generated file and, for the remaining Jupyter Notebooks to work without changes, the annotators must stick to the following three classes: *positive*, *negative* and *neutral*. For example, the annotations for the words *good*, *bad* and *house* could be:\n",
    "\n",
    "word | sentiment\n",
    "--- | ---\n",
    "good | positive\n",
    "bad\t| negative\n",
    "house |\tneutral\n",
    "\n",
    "However, other expressions of sentiment, such as additional classes or numerical values, may be used if the subsequent Jupyter Notebooks are adjusted accordingly.\n",
    "\n",
    "#### Selecting Seed Words\n",
    "\n",
    "As past research has indicated that sentiment is very subjective and involves disagreement between multiple individuals (Mozetič et al. 2016), we need to implement a selection procedure to settle on the final sentiment of frequent words.\n",
    "For that, we use a simple majority vote, in which we only keep words for which at least two annotators have equal annotations and in which we remove the remaining words otherwise.\n",
    "Regarding the number of annotators, we suggest employing as many of them as possible as it allows for better generalization.\n",
    "Naturally, there is a trade-off between the number of annotators you can find/afford (i.e., it is very time-consuming to annotate words, especially when you have to consider the sociocultural context) and the quality of resulting annotations.\n",
    "In our case, we went with three (which we consider the lowest limit) annotators per language, who have all worked with the data for several years and have an extensive knowledge about this period in time.\n",
    "\n",
    "The Jupyter Notebook (see `code/dictionary_creation/1_seed_words/3_selection.ipynb`) for the selection of seed words provides a ready-to-use implementation based on a majority vote. In the following table, we provide the number of positive, negative and neutral selected seed words:\n",
    "\n",
    "Language | # positive | # negative | # neutral\n",
    "--- | --- | --- | --- \n",
    "French | 803 | 381 | 1,738 \n",
    "Italian | 1,811 | 244 | 838\n",
    "Spanish | 385 | 251 | 2,340"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Creating Word Embeddings\n",
    "\n",
    "Computers have hard times working with texts or words.\n",
    "To counteract this problem, we need to transform texts or words into numerical forms.\n",
    "One way to achieve this are so-called word embeddings, which represent words by vectors.\n",
    "Existing research discerns two types of word embeddings: (i) frequency-based word embeddings, such as count vectors or TF-IDF vectors, as well as prediction-based word embeddings, such as word2vec (Mikolov et al. 2013).\n",
    "\n",
    "Before describing our utilized method, we want to demonstrate principles of word embeddings in the following example.\n",
    "For that, consider the following three sentences contained in a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_sentences = [\n",
    "    \"Word embeddings are fun.\",\n",
    "    \"It is fun to learn new things.\",\n",
    "    \"Teaching word embeddings is also fun.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `CountVectorizer` from the `scikit-learn` package to create a count matrix and store that in a pandas `DataFrame` for easier interpretation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CountVectorizer' object has no attribute 'get_feature_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m vectorizer \u001b[38;5;241m=\u001b[39m CountVectorizer()\n\u001b[0;32m      2\u001b[0m count_matrix \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mfit_transform(example_sentences)\n\u001b[1;32m----> 3\u001b[0m count_vectors_df \u001b[38;5;241m=\u001b[39m pandas\u001b[38;5;241m.\u001b[39mDataFrame(count_matrix\u001b[38;5;241m.\u001b[39mtodense(), columns\u001b[38;5;241m=\u001b[39m\u001b[43mvectorizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_feature_names\u001b[49m())\n\u001b[0;32m      4\u001b[0m display(count_vectors_df)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'CountVectorizer' object has no attribute 'get_feature_names'"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "count_matrix = vectorizer.fit_transform(example_sentences)\n",
    "count_vectors_df = pandas.DataFrame(count_matrix.todense(), columns=vectorizer.get_feature_names())\n",
    "display(count_vectors_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can now observe, this produces a table in which each row represents one of the three sentences and each column represents a distinct word occurring in either of the three sentences.\n",
    "Each value in the cells of the table equals 1 if the respective word occurs in the respective sentence or 0 otherwise.\n",
    "We can then find the vector representation of a word by considering the values in its column.\n",
    "For example, the vector of the word *embeddings* is `[1, 0, 1]` and of the word *fun* is `[1, 1, 1]`.\n",
    "Thus, a word is represented by the set of sentences/documents in which it occurs.\n",
    "\n",
    "Word embeddings also capture the context of a word in a document, including the semantic similarity as well as the relations with other words.\n",
    "As such, vectors of words that are frequently used together in texts are also very close to each other in the resulting vector space.\n",
    "Contrary, vectors of words that are never or only minimally used in a similar context should be very distant from each other.\n",
    "This suits perfectly for our dictionary creation process and based on the vector representation of words, we can automatically transfer sentiment from our seed words to other words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word2Vec\n",
    "\n",
    "For our dictionary creation pipeline we rely on word2vec (Mikolov et al. 2013), a state-of-the-art method to compute word embeddings.\n",
    "Word2vec relies on a two-layer neural network to train word vectors that capture the linguistic contexts of words and comprises either one of two different model architectures: continuous bag-of-words (CBOW) or skip-gram.\n",
    "The former predicts a word from a given context whereas the latter predicts the context from a given word.\n",
    "Both have their advantages and disadvantages regarding the size of the underlying text corpus, which is why we consider both of them in our tool chain.\n",
    "\n",
    "Before talking about the specifics of our approach, we want to demonstrate the benefits of word2vec. For the following example, we used Gensim's word2vec implementation to train word embeddings of the publicly available *text8* dataset. We can load the pretrained word2vec model with the following line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = Word2Vec.load(\"data/processed_data/word2vec_models/example.p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we used the default parameters for word2vec as implemented in Gensim, we trained vectors with a dimension of 100. Thus, instead of the three numbers in a vector from the count vector example above, we now have 100 numbers (i.e., a vector of length 100).\n",
    "Moreover, these numbers are now real-valued instead of integers and their interpretation is less self-evident.\n",
    "We can inspect the resulting vector of a word, for example *car*, with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(word2vec_model.wv[\"car\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find words similar to *car* by considering the cosine similarity between the vector of *car* and all other vectors. The higher the similarity, the more similar the words are. Gensim provides an easy way to find most similar words based on cosine similarity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model.wv.most_similar(\"car\", topn=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another advantage of word2vec compared to count vectors is that it can capture various concepts and analogies.\n",
    "Perhaps the most famous example in that regard is as follows: If you subtract the vector of the word *man* from the vector of the word *king* and add the vector of the word *woman* it should result in a vector very close to that of the word *queen*. We can evaluate whether this is the case with our pretrained model through Gensim very easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model.wv.most_similar(positive=[\"woman\", \"king\"], negative=[\"man\"], topn=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that, indeed, the trained word embedding correctly reflects this analogy.\n",
    "Can you think of any other concepts or analogies to test? Feel free to try it with other word vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the Models\n",
    "\n",
    "Before we start training the actual word2vec models for the Spectator periodicals in the respective languages, we need to preprocess our texts.\n",
    "The amount of required preprocessing for word2vec is very minimal, as we only need to remove stop words and extract individual sentences.\n",
    "The latter is important because individual sentences are the required input form for the word2vec implementation of Gensim.\n",
    "\n",
    "Since word2vec has many hyperparameters (that all have an impact on the resulting word embeddings), we need to tune them to achieve the best possible performance.\n",
    "One way to optimize hyperparameters is to conduct a *grid search*.\n",
    "For this purpose, we define a set of possible hyperparameters and train one individual model for each possible hyperparameter combination.\n",
    "We then evaluate each model and select the one that yielded the best performance. \n",
    "The Jupyter Notebook (see `code/dictionary_creation/2_word_embeddings/1_grid_search.ipynb`) contains a selection of possible hyperparameters, but further adjustments may be necessary.\n",
    "For that, we refer to the [documentation](https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec) (Řehůřek 2009-2021) of the word2vec implementation of Gensim.\n",
    "\n",
    "All models trained this way are stored for later use and, depending on your text corpus and the number of hyperparameter combinations, the file size of stored models can take hundreds of gigabytes.\n",
    "\n",
    "#### Evaluating the Models\n",
    "\n",
    "Once we trained one model for each hyperparameter combination, we needed to evaluate which of these combinations achieved the best performance.\n",
    "For this evaluation, we rely on lists of manually annotated word pairs, in which every word pair was assigned to a relation score.\n",
    "In our case, this relation score ranges from 0 to 10, where 0 represents no similarity and 10 represents absolute similarity.\n",
    "For example, when we consider the word pairs *old & new*, *easy & hard*, *beautiful & wonderful* as well as *rare & scarce*, the respective scores could be:\n",
    "\n",
    "word pair | relation score\n",
    "--- | ---\n",
    "old & new | 0\n",
    "easy & hard\t| 1.23\n",
    "beautiful & wonderful |\t7.15\n",
    "rare & scarce | 9.89\n",
    "\n",
    "Typically, such word pair lists are manually annotated, which is again a very time-consuming and tedious process and requires multiple annotators. In our case, we adapt previously existing lists for French, Italian and Spanish (Freitas et al. 2016; [GitHub Repository](https://github.com/siabar/Multilingual_Wordpairs)).\n",
    "More precisely, we filter all words that are not existing in our historic Spectator periodicals, extend lists with spelling variations of the 18<sup>th</sup> century as well as check whether relation scores are meaningful and also applicable to the languages of the 18<sup>th</sup> century.\n",
    "\n",
    "Using the adapted lists, we can compute Pearson correlation coefficients between scores of word pairs and similarities of respective word vectors from the trained models in our dedicated Jupyter Notebook (see `code/dictionary_creation/2_word_embeddings/2_evaluation.ipynb`).\n",
    "We then select the model for which the correlation coefficients are the highest and report the following coefficients for the respective languages:\n",
    "\n",
    "Language | Pearson Rho \n",
    "--- | --- \n",
    "French | 0.402 \n",
    "Italian | 0.157\n",
    "Spanish | 0.310\n",
    "\n",
    "We provide the selected models in the data folder of this repository.\n",
    "To use them for your own projects, download them and load the pickled Gensim word2vec model in Python:\n",
    "\n",
    "```python\n",
    "import pickle\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "path_to_model = \"\" # set the path to where you saved the model (e.g., path_to_model=\"french.p\")\n",
    "\n",
    "with open(path_to_model, \"rb\") as handle:\n",
    "    model = pickle.load(handle)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Transferring Sentiment\n",
    "\n",
    "In the third and final step of the dictionary creation pipeline, we use the generated word embeddings to transfer the sentiment from our seed words to other words that appear in a similar context of seed words.\n",
    "For that, we use a *k*-nearest neighbors (KNN) classifier (Fix and Hodges 1951) that considers the distances between word vectors.\n",
    "Remember that the trained word embeddings keep words that appear frequently in a similar context close together and words that are not related very distant from each other in the vector space.\n",
    "As such, this straightforward and interpretable classification method is perfectly suited for our context-based transfer of sentiment.\n",
    "\n",
    "#### Classifying Words\n",
    "\n",
    "The *k*-nearest neighbors classifier is based on distances between vectors in a multidimensional feature space (in our case the vectors from the trained word embeddings).\n",
    "It classifies an unlabeled instance based on the *k*-nearest labeled neighbors of that instance, where *k* can take an arbitrary value.\n",
    "\n",
    "To demonstrate the functioning of the KNN classifier, we implement a two-dimensional example in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "example_X_data = [\n",
    "    [2, 2],\n",
    "    [3, 5],\n",
    "    [4, 8],\n",
    "    [5, 2],\n",
    "    [6, 9],\n",
    "    [2, 6],\n",
    "    [8, 7]\n",
    "]\n",
    "\n",
    "example_X_labels = [\n",
    "    \"blue\",\n",
    "    \"red\",\n",
    "    \"red\",\n",
    "    \"blue\",\n",
    "    \"red\",\n",
    "    \"red\",\n",
    "    \"blue\"\n",
    "]\n",
    "\n",
    "example_y_data = [\n",
    "    [3, 3]\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.scatter(*zip(*example_X_data), c=example_X_labels)\n",
    "ax.scatter(*zip(*example_y_data), c=\"black\", marker=\"x\")\n",
    "ax.set_xlim(0, 10)\n",
    "ax.set_ylim(0, 10)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we have two different classes (or labels): the *blue* points and the *red* points.\n",
    "We have one unlabeled instance, in this case a black cross, which we want to assign to either of the two classes.\n",
    "The resulting class for the unlabeled instance depends on how we set *k*.\n",
    "Note that for a binary classification task (two classes), only odd numbers for *k* make sense as it could result in ties otherwise.\n",
    "\n",
    "Now we can train the classifier based on the labeled instances using the `KNeighborsClassifier` method from `scikit-learn`, which finds the nearest neighbors of our unlabeled instance and assigns it to the majority class of these neighbors. For this example, we set *k* to 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "neigh = KNeighborsClassifier(n_neighbors=k)\n",
    "neigh.fit(example_X_data, example_X_labels)\n",
    "\n",
    "nearest_neighbors = neigh.kneighbors(example_y_data)[1][0]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.scatter(*zip(*example_X_data), c=example_X_labels)\n",
    "ax.scatter(*zip(*example_y_data), c=\"black\", marker=\"x\")\n",
    "for n_i in nearest_neighbors:\n",
    "    ax.plot([example_y_data[0][0], example_X_data[n_i][0]], [example_y_data[0][1], example_X_data[n_i][1]], 'gray', linestyle=':', marker='')\n",
    "ax.set_xlim(0, 10)\n",
    "ax.set_ylim(0, 10)\n",
    "plt.show()\n",
    "plt.close()\n",
    "Markdown(\"The unlabeled instance is assigned to the *{}* class.\".format(neigh.predict(example_y_data)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For *k* = 3, the algorithm considers the three nearest neighbors (indicated by the dashed gray lines)  which include one instance of the *red* class and two instances of the *blue* class.\n",
    "As the majority of neighbors are labeled *blue*, it assigns our unlabeled instance to the *blue* class.\n",
    "But what about other values of *k*? Feel free to adjust *k* in the above code block and observe the different outcomes.\n",
    "For example, in the case of *k* = 5, the classifier considers the five nearest neighbors, three of which are labeled *red* and two of which are labeled *blue*.\n",
    "Thus, it assigns our unlabeled instance to the *red* class.\n",
    "\n",
    "As you can see, the selection of *k* has a crucial impact on the result of the classification.\n",
    "Further, there are additional hyperparameters for this classifier that affect the classification outcome, such as the distance measure to find the nearest neighbors.\n",
    "For word embeddings (e.g., TF-IDF, word2vec), we suggest to use cosine similarity because directions of vectors are more important than magnitudes of vectors.\n",
    "We specifically advise against the Euclidean distance for such high dimensional cases as vectors tend to become uniformly distant from each other with this metric.\n",
    "To counteract the problem of the hyperparameter selection, one could conduct a grid search (similar to what we have done for the word2vec model) and evaluate the classified words with a test set containing a ground truth.\n",
    "For our case, we decided to set *k* to 5 (a common value for *k*) and to evaluate the performance of our model as described in the following section.\n",
    "\n",
    "Regarding the classification based on our previously trained word embeddings, we provide all code to train the classifier with the word vectors of seed words and then to predict the sentiment class (i.e., positive, negative or neutral) for all remaining words in the text corpus in the Jupyter Notebook (see `code/dictionary_creation/3_classification/1_knn.ipynb`).\n",
    "\n",
    "#### Evaluating the Classification\n",
    "\n",
    "To evaluate the performance of the classifier, we randomly extract a maximum of 1,000 words from each of the three assigned sentiment classes and manually annotate them.\n",
    "Note that the Jupyter Notebook (see `code/dictionary_creation/3_classification/2_evaluation.ipynb`) for the classifier evaluation provides a way to randomly extract words and to prepare *.csv* files for further annotation.\n",
    "In our work, we again let three expert annotators label the cumulated 3,000 words, respectively for each language (except for Spanish for which the classifier labeled only 649 positive and 440 negative words).\n",
    "Similar to the annotation process for seed words, we only keep the annotated words for which at least two annotators agreed (majority vote).\n",
    "We then compute balanced accuracy scores (between the labels assigned by the classifier and the labels assigned by the annotators) to assess the prediction performance of our classifier and, thus, the quality of our computationally created dictionaries.\n",
    "We report the following balanced accuracy scores:\n",
    "\n",
    "Language | Balanced Accuracy | Bootstrap Confidence Interval\n",
    "--- | --- | ---\n",
    "French | 0.570 | [0.554, 0.597]\n",
    "Italian | 0.544 | [0.526, 0.563]\n",
    "Spanish | 0.554 | [0.530, 0.580]\n",
    "\n",
    "These values indicate that we outperform a random baseline (0.33) and are similar to other automated sentiment classification tasks in terms of performance (Mozetič et al. 2016).\n",
    "However, note that we did not evaluate all the words labeled by the KNN classifiers but only a small and randomly drawn subset of them. To mitigate the effect of the one-time random extraction of evaluation words, in the table above we also provide bootstrap 95% confidence intervals (over 1,000 iterations) to estimate the balanced accuracy of the whole population for each language.\n",
    "\n",
    "This step concludes the dictionary creation process. We provide in-depth descriptions of how to use the created dictionaries for sentiment analysis in the following section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis for the 18<sup>th</sup> Century\n",
    "\n",
    "In this section, we  demonstrate how to utilize our created dictionaries to analyze sentiment of Spectator periodicals published during the 18<sup>th</sup> century. The related Jupyter Notebooks can be found in the `code/sentiment_analysis/` directory of this repository.\n",
    "\n",
    "### French, Italian and Spanish Dictionaries\n",
    "\n",
    "You can use our created sentiment dictionaries for French, Italian and Spanish for your own projects.\n",
    "In particular, we provide three different forms of dictionaries for each of the three languages.\n",
    "We provide detailed descriptions of them in the following sections.\n",
    "\n",
    "#### Manually Annotated\n",
    "The first kind of dictionaries contains all the manually annotated words used for the seed word selection and the evaluation of the KNN classifiers.\n",
    "For each language, we provide a list of positive, negative and neutral words.\n",
    "All words have been manually annotated by three experts familiar with the Spectator periodicals.\n",
    "To assess the agreement between annotators, we report the Fleiss' kappa (Fleiss 1971), respectively for annotated words used in the seed word selection as well as in the evaluation of KNN classifiers:\n",
    "\n",
    "*Fleiss' kappa between the three annotators for words used in the seed word selection:*\n",
    "\n",
    "Language | kappa \n",
    "--- | --- \n",
    "French | 0.387 \n",
    "Italian | 0.385 \n",
    "Spanish | 0.370\n",
    "\n",
    "*Fleiss' kappa between the three annotators for words used in the KNN classifiers evaluation:*\n",
    "\n",
    "Language | kappa \n",
    "--- | --- \n",
    "French | 0.127 \n",
    "Italian | 0.328 \n",
    "Spanish | 0.300\n",
    "\n",
    "These values suggest a fair agreement between annotators and reflect the typical discrepancies between individuals regarding sentiment (Mozetič et al. 2016).\n",
    "Note that we only keep the words for which at least two annotators agreed (majority vote).\n",
    "In the following table, we list the number of positive, negative and neutral words in the manually annotated dictionaries, respectively for each language:\n",
    "\n",
    "Language | # positive | # negative | # neutral\n",
    "--- | --- | --- | --- \n",
    "French | 1,045 | 1,071 | 3,150 \n",
    "Italian | 1,789 | 1,196 | 2,696\n",
    "Spanish | 681 | 798 | 3,529\n",
    "\n",
    "#### Computationally Extended\n",
    "The second kind of dictionaries contain all manually annotated seed words as well as words for which we transferred sentiment through our KNN classification.\n",
    "Note that these dictionaries are very specific to our text corpus (Spectator periodicals).\n",
    "If you are considering other data, you may want to use manually annotated words only or create extended dictionaries yourself.\n",
    "In the following table, we list the number of positive, negative and neutral words in the computationally extended dictionaries, respectively for each language:\n",
    "\n",
    "Language | # positive | # negative | # neutral\n",
    "--- | --- | --- | --- \n",
    "French | 4,713 | 2,350 | 17,499 \n",
    "Italian | 4,365 | 1,652 | 25,494\n",
    "Spanish | 1,034 | 691 | 19,070\n",
    "\n",
    "Note that the number of negative Spanish words for the computationally created dictionary is smaller than the one for manually created dictionaries even though we include seed words here.\n",
    "This is due to the fact that the manually annotated dictionary includes both annotated seed words as well as annotated words for the classifier evaluation. In the case of Spanish, we have 251 negative seed words and the classifier only transferred the negative sentiment to 440 unlabeled words and, thus, making the number smaller compared to the manually created Spanish dictionary.\n",
    "\n",
    "#### Computationally Extended and Corrected\n",
    "The third group of dictionaries contains manually annotated seed words and computationally extended words but the latter were corrected using the manually annotated words used in the evaluation of the KNN classifiers.\n",
    "For example, if the KNN classifier labeled a word as positive but at least two annotators labeled it differently for the evaluation, we changed the sentiment class to that of the agreeing annotators.\n",
    "In the following table, we list the number of positive, negative and neutral words in the computational extended and corrected dictionaries, respectively for each language:\n",
    "\n",
    "Language | # positive | # negative | # neutral\n",
    "--- | --- | --- | --- \n",
    "French | 4,216 | 2,272 | 18,074 \n",
    "Italian | 4,387 | 1,674 | 25,450\n",
    "Spanish | 692 | 812 | 19,291\n",
    "\n",
    "#### Loading the Dictionaries\n",
    "Since the dictionaries are plain text files, you can easily load them in Python. For the subsequent demonstration of analysis methods, we use the computationally extended and corrected Spanish dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = \"Spanish\"\n",
    "sentiment_dict = {}\n",
    "with open(\"{}{}_negative.txt\".format(\"data/processed_data/dictionaries/computational_corrected/\", language.lower()), \"r\", encoding=\"utf-8\") as fr:\n",
    "    sentiment_dict[\"neg\"] = fr.read().splitlines()\n",
    "with open(\"{}{}_positive.txt\".format(\"data/processed_data/dictionaries/computational_corrected/\", language.lower()), \"r\", encoding=\"utf-8\") as fr:\n",
    "    sentiment_dict[\"pos\"] = fr.read().splitlines()\n",
    "\n",
    "print(\"loaded {} negative words\".format(len(sentiment_dict[\"neg\"])))\n",
    "print(\"loaded {} positive words\".format(len(sentiment_dict[\"pos\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Your Data\n",
    "\n",
    "We have now successfully loaded the sentiment dictionaries but before we can use them for the sentiment analysis, we have to prepare our data.\n",
    "Analyzing sentiment with our Jupyter Notebook requires a specific data format which allows for additional attributes, such as author names or publication dates, to be considered.\n",
    "To add custom attributes, one needs to append them before the text in the respective *.txt* files.\n",
    "The Jupyter Notebook (see `code/sentiment_analysis/1_data_preparation.ipynb`) utilized for the data preparation extracts the text as well as additional attributes and stores them in a pandas DataFrame.\n",
    "\n",
    "The following file format must be satisfied:\n",
    "\n",
    "* Each additional attribute must be provided in an individual line in the text file.\n",
    "* A line containing an attribute needs to begin with its name followed by an `=` and then the value for the attribute. No spaces between the `=` and attribute name/value are allowed. For example: `year=1786`.\n",
    "* The number of additional attributes to provide is unlimited, however, attribute names must be unique.\n",
    "* Attribute names can include spaces. For example: `periodical title=La Spectatrice`.\n",
    "* The actual text must be provided at last following a `text=` at the beginning of the line.\n",
    "* Line breaks in the text are allowed, just not for attribute values.\n",
    "\n",
    "The following snippet depicts an input *.txt* file in the correct format:\n",
    "\n",
    "```\n",
    "year=1711\n",
    "author=Justus Van Effen\n",
    "text=Si je prends la liberté de vous dédier cet Ouvrage; ce n’est en aucune maniere pour me ménager une favorable occasion d’instruire les hommes de votre mérite, & de vous donner, même avec sobrieté, les éloges dont vous êtes digne...\n",
    "```\n",
    "Note that the inclusion of additional attributes is optional and *.txt* can start with the text right away. For example:\n",
    "\n",
    "```\n",
    "text=Si je prends la liberté de vous dédier cet Ouvrage; ce n’est en aucune maniere pour me ménager une favorable occasion d’instruire les hommes de votre mérite, & de vous donner, même avec sobrieté, les éloges dont vous êtes digne...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, we already transformed French, Italian and Spanish texts into respective pandas DataFrames. If you want to see the code for this process please refer to the corresponding Jupyter Notebook in the code folder. Further, we provide the individual *.txt* files for each language in the `data/raw_data/example_texts/` directory of this repository if you wish to reconstruct the DataFrame creation yourself.\n",
    "\n",
    "Now we can load the pandas DataFrame containing Spanish texts as well as four additional attributes (i.e., periodical title, issue number, author, year) as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_df = pandas.read_pickle(\"data/processed_data/example_texts/spanish.p\")\n",
    "print(\"loaded dataframe with {} texts and {} attributes\".format(texts_df.shape[0], texts_df.shape[1] - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Sentiment\n",
    "\n",
    "By now, we have loaded our sentiment dictionaries as well as our texts. To compute sentiment, we have to consider the occurrences of the words contained in the dictionaries in the text files.\n",
    "For that, we use the following formula, defining the sentiment *s* of a text with:\n",
    "\n",
    "![Sentiment Formula](miscellaneous/sentiment_formula_2.png)\n",
    "\n",
    "where $W_p$ is the number of positive words in a text and $W_n$ is the number of negative words in a text.\n",
    "Thus, the computed sentiment score is a value ranging between −1 and +1, where values close to −1 are considered as negative, values close to +1 as positive, and where values close to zero indicate a neutral sentiment.\n",
    "The implementation of this formula in Python is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sentiment(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [t.lower() for t in tokens]\n",
    "    num_negative = 0\n",
    "    num_positive = 0\n",
    "    for nw in sentiment_dict[\"neg\"]:\n",
    "        num_negative += tokens.count(nw.lower())\n",
    "    for pw in sentiment_dict[\"pos\"]:\n",
    "        num_positive += tokens.count(pw.lower())\n",
    "    try:\n",
    "        sentiment_score = (num_positive - num_negative) / (num_positive + num_negative)\n",
    "    except ZeroDivisionError:\n",
    "        sentiment_score = 0\n",
    "    return sentiment_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After defining our method to compute sentiment, we have to apply it to the respective texts. Doing this with pandas in Python requires one line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_df[\"sentiment\"] = texts_df[\"text\"].apply(compute_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing Sentiment\n",
    "\n",
    "After computing the sentiment for the individual texts, we can start analyzing the text corpus by considering descriptive statistics. We can compute and print these statistics with pandas through the `describe` method (read more about it in the official [pandas documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_df[\"sentiment\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method returns the count, mean, median, standard deviation, minimum, maximum as well as the first (25<sup>th</sup> percentile) and third (75<sup>th</sup> percentile) quartile and, thus, provides an idea about the sentiment distribution in the analyzed texts. For better visualization, we can create a histogram plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_df[\"sentiment\"].plot(kind=\"hist\", bins=10)\n",
    "plt.xlabel(\"Sentiment\")\n",
    "plt.title(\"Histogram Plot Example\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the figure above, we can observe that the majority of texts in our dataset convey a positive sentiment and only a small number of texts a slightly negative one.\n",
    "Whether this allows statements about the Spanish corpus of periodicals as a whole or whether there is a bias can only be judged by comparing the results with a different Spanish corpus of 18<sup>th</sup> century texts.\n",
    "We thus concentrate on comparisons within the present corpus by considering the additional attributes.\n",
    "\n",
    "We can use other types of plots to investigate the interaction of sentiment with the additional attributes we provided.\n",
    "For example, we can create a box plot to assess sentiment distribution differences between two Spectator periodicals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "texts_df.boxplot(\"sentiment\", by=\"periodical title\")\n",
    "plt.ylabel(\"Sentiment\")\n",
    "plt.title(\"Box Plot Example\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Box plots are a convenient approach to learn more about the distribution of the underlying data.\n",
    "The horizontal green lines indicate medians, while the blue lines indicate the first and third quartiles.\n",
    "The whiskers (horizontal black lines) indicate minimum and maximum values still within 1.5 interquartile ranges.\n",
    "In the above figure, we observe that Joseph Clavijo y Faxardo's *El Pensador* (1762-63, 1767) conveyed a more positive sentiment as compared to Beatriz Cienfuegos' *La Pensadora Gaditana* (1763-64).\n",
    "\n",
    "Another interesting example is the development of sentiment over the publication period of the individual issues of the two periodicals. We can use seaborn's `lineplot` method to easily create a plot for this comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.lineplot(data=texts_df, x=\"issue number\", y=\"sentiment\", hue=\"periodical title\")\n",
    "plt.title(\"Line Plot Example\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above figure we observe that the sentiment is changing significantly over the issues of both periodicals.\n",
    "\n",
    "Further, we can analyze sentiment of individual texts contained in our dataset.\n",
    "The following code block prints and highlights all the words conveying sentiment in a single text (in this case we consider *Prólogo y Razón de la Obra* of *La Pensadora Gaditana*):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_print = texts_df.loc[\"mws-08C-52.txt\", \"text\"]\n",
    "\n",
    "# If you want to try this here with your own texts, please replace 'texts_df.loc[\"mws-08C-52.txt\", \"text\"]' with your own text.\n",
    "# For example:\n",
    "# text_to_print = \"Yo, señores, gozo la suerte de ser hija de Cadiz: bastante he dicho para poder hablar sin verguenza...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nw in sentiment_dict[\"neg\"]:\n",
    "    if nw.lower() in text_to_print.lower() and nw not in [\"span\", \"style\", \"color\", \"font\", \"size\"]:\n",
    "        text_to_print = re.sub(r\"\\b{}\\b\".format(nw), r\"<span style='color:#E74C3C; font-size:20pt'><b>{}</b></span>\".format(nw), text_to_print)\n",
    "        \n",
    "for pw in sentiment_dict[\"pos\"]:\n",
    "    if pw.lower() in text_to_print.lower() and pw not in [\"span\", \"style\", \"color\", \"font\", \"size\"]:\n",
    "        text_to_print = re.sub(r\"\\b{}\\b\".format(pw), r\"<span style='color:#27AE60; font-size:20pt'><b>{}</b></span>\".format(pw), text_to_print)\n",
    "\n",
    "HTML(text_to_print)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above methods only demonstrate some examples of how to analyze and visualize sentiment. We provide a variety of other sentiment analysis methods in the corresponding Jupyter Notebook (see `code/sentiment_analysis/2_sentiment_analysis.ipynb`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitations and Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this work, we proposed a method to create sentiment dictionaries specifically designed for the analysis of Spectator periodicals published in French, Italian and Spanish during the 18<sup>th</sup> century. We extracted, annotated and selected a set of seed words for each language which we then used to transfer sentiment to other words based on a classification task relying on trained word embeddings. Further, we evaluated the performance of both the creation of word embeddings and the conducted classification.\n",
    "\n",
    "Machine learning techniques are criticized as lacking transparency and consistency, as well as to require a large amount of training data from a respective domain (Cambria et al. 2017, 74). We tried to address this critique by selecting inherently interpretable methods, such as dictionary-based sentiment analysis and classification based on nearest neighbors. In addition to the mentioned challenges with analyzing non-English historical texts, sentiment analysis faces other limitations regarding tasks of natural language processing, which Cambria et al. (2017, 75-78) separate in three layers: syntactics, semantics, and pragmatics. These include challenges of preprocessing, extracting concepts and meaning, filtering out neutral content, and interpreting metaphors. Schmidt et al. (2018, 6-7) also point out how dictionary-based sentiment analysis faces limitations in trying to determine opinion orientation expressed using opinion shifters (like irony or sarcasm), ambiguity or broader context. Another challenge we acknowledge is the human uncertainty involved in the annotation process of corpora (Schmidt et al. 2018, 6-7), which needs to be considered when conducting sentiment analysis. As such, sentiment analysis serves to extend the knowledge about our data and results based on machine learning methods should always be considered with caution. The subsequent interpretation through experts familiar with the content and context is necessary.\n",
    "\n",
    "Leaving these limitations aside, our tool chain can be easily adapted and can serve as a foundation for future work. While the current setup is easily accessible due to all methods being interpretable and thus perfectly suited for the classroom in digital literary studies curricula, it also provides a skeleton within which researchers can exchange code blocks (embedding techniques, classification methods, etc.) with better performing state-of-the-art methods. This leaves us confident to believe that our work is a useful contribution to the currently ongoing discussion on the application of computational methods to historical texts both, in digital humanities in general and in (digital) literary studies in specific.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledgments\n",
    "\n",
    "This work was funded by CLARIAH-AT and partly funded by the go!digital program of the Austrian Academy of Sciences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Cambria, E.; Poria, S.; Gelbukh, A. & Mike Thelwall (2017). Sentiment Analysis Is a Big Suitcase. In IEEE Intelligent Systems, Vol. 32/6, Nov./Dec. 2017, pp. 74-80. DOI: 10.1109/MIS.2017.4531228.\n",
    "\n",
    "Ertler, K.-D. (2004). Tugend und Vernunft in der Presse der spanischen Aufklärung: El Censor, Tübingen, Narr.\n",
    "\n",
    "Ertler, K.-D.(2012). «Moral Weeklies (Periodical Essays)», European History Online (EGO), http://www.ieg-ego.eu/ertlerk-2012-en.\n",
    "\n",
    "Ertler, K.-D., Fuchs A., Fischer-Pernkopf M., Hobisch E., Scholger M. & Völkl Y. (2011-2021). The Spectators in the International Context. https://gams.uni-graz.at/spectators.\n",
    "\n",
    "Fischer, M. (2014). Die Figur des Lesers im Kommunikationssystem der Spectateurs, Frankfurt a. M., Peter Lang.\n",
    "\n",
    "Fischer-Pernkopf, M., Mussner, V. & Ertler, K.-D. (2018). Die «Spectators» in Frankreich. «Le Nouveau Spectateur» und «Le Monde comme il est» von Jean-François de Bastide, Frankfurt a. M., Peter Lang.\n",
    "\n",
    "Fix, E., & Hodges, J. L. (1951). Nonparametric discrimination: Consistency properties. Randolph Field, Texas, Project, 21-49.\n",
    "\n",
    "Fleiss, J. L. (1971). Measuring nominal scale agreement among many raters. Psychological bulletin, 76(5), 378.\n",
    "\n",
    "Freitas, A., Barzegar, S., Sales, J. E., Handschuh, S., & Davis, B. (2016). Semantic relatedness for all (languages): A comparative analysis of multilingual semantic relatedness using machine translation. In *European Knowledge Acquisition Workshop*, 212-222. Springer, Cham.\n",
    "\n",
    "Hamilton, W. L., Clark, K., Leskovec, J., & Jurafsky, D. (2016). Inducing domain-specific sentiment lexicons from unlabeled corpora. In *Proceedings of the Conference on Empirical Methods in Natural Language Processing. Conference on Empirical Methods in Natural Language Processing*, Vol. 2016, 595). NIH Public Access.\n",
    "\n",
    "Hatzivassiloglou, V., & McKeown, K. (1997, July). Predicting the semantic orientation of adjectives. In *35th annual meeting of the association for computational linguistics and 8th conference of the European chapter of the association for computational linguistics*, 174-181).\n",
    "\n",
    "Hearst, M. A. (1992). Direction-based text interpretation as an information access refinement. *Text-based intelligent systems: current research and practice in information extraction and retrieval*, 257-274.\n",
    "\n",
    "Henny-Krahmer, U. (2018): Exploration of Sentiments and Genre in Spanish American Novels. https://dh2018.adho.org/exploration-of-sentiments-and-genre-in-spanish-american-novels/.\n",
    "\n",
    "Hobisch, E. (2017). La forma epistolar en los espectadores españoles. Características y tipología de las cartas,  Frankfurt a. M., Peter Lang.\n",
    "\n",
    "Jannidis, F., Reger, I., Zehe, A., Becker, M., Hettinger, L., & Hotho, A. (2017, February 14). Analyzing Features for the Detection of Happy Endings in German Novels. In *DHd 2017* - Digitale Nachhaltigkeit. 4. Tagung des Verbands \"Digital Humanities im deutschsprachigen Raum\" (DHd 2017), Bern. DOI: 10.5281/zenodo.4622783\n",
    "\n",
    "Kay, D. (1975). Short Fiction in 'The Spectator', Alabama, University of Alabama Press.\n",
    "\n",
    "Kim, E., & Klinger, R. (2019). A Survey on Sentiment and Emotion Analysis for Computational Literary Studies. In *Zeitschrift für digitale Geisteswissenschaften*. Wolfenbüttel 2019. text/html Format. DOI: 10.17175/2019_008.\n",
    "\n",
    "Kim, E., Padó, S., & Klinger, R. (2017). Prototypical Emotion Developments in Literary Genres. In *Proceedings of the Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature*, 17-26.\n",
    "\n",
    "Kühlmann, W. (2012). «Moralische Aufklärung im 18. Jahrhundert. Ziele, Medien, Aporien», in M.S. Doms and B. Walcher (eds.), Periodische Erziehung des Menschengeschlechts. Moralische Wochenschriften im deutschsprachigen Raum, Bern, Peter Lang, 15-46.\n",
    "\n",
    "Lévrier, A. (2007). Les journaux de Marivaux et le monde des ‘spectateurs’, Paris, PUPS.\n",
    "\n",
    "Liu, B. (2020). Sentiment analysis: Mining opinions, sentiments, and emotions. Cambridge university press.\n",
    "\n",
    "Liu, B., & Zhang, L. (2012). A survey of opinion mining and sentiment analysis. In *Mining text data*, 415-463. Springer, Boston, MA.\n",
    "\n",
    "Maas, A., Daly, R. E., Pham, P. T., Huang, D., Ng, A. Y., & Potts, C. (2011, June). Learning word vectors for sentiment analysis. In *Proceedings of the 49th annual meeting of the association for computational linguistics: Human language technologies*, 142-150.\n",
    "\n",
    "Mikolov, T., Chen, K., Corrado, G., & Dean, J. (2013). Efficient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781.\n",
    "\n",
    "Mozetič, I., Grčar, M., & Smailović, J. (2016). Multilingual Twitter sentiment classification: The role of human annotators. PloS one, 11(5), e0155036.\n",
    "\n",
    "Nasukawa, T., & Yi, J. (2003, October). Sentiment analysis: Capturing favorability using natural language processing. In *Proceedings of the 2nd international conference on Knowledge capture*, 70-77.\n",
    "\n",
    "Ortigosa, A., Martín, J. M., & Carro, R. M. (2014). Sentiment analysis in Facebook and its application to e-learning. Computers in human behavior, Vol. 31, 527-541.\n",
    "\n",
    "Pak, A., & Paroubek, P. (2010). Twitter as a corpus for sentiment analysis and opinion mining. In *LREc*, Vol. 10, No. 2010, 1320-1326.\n",
    "\n",
    "Pang, B. & Lee, L. (2008). Opinion Mining and Sentiment Analysis. In *Foundations and Trends® in Information Retrieval*, Vol. 2, No. 1–2, 1-135. DOI: 10.1561/1500000011\n",
    "\n",
    "Rau, F. (1980). Zur Verbreitung und Nachahmung des Tatler und Spectator, Heidelberg, Winter.\n",
    "\n",
    "Řehůřek, R. (2009-2021). Word2vec embeddings. https://radimrehurek.com/gensim/models/word2vec.html\n",
    "\n",
    "Schmidt, T., Burghardt, M. & Wolff, C. (2018). Herausforderungen für Sentiment Analysis-Verfahren bei literarischen Texten. In Burghardt, M. & Müller-Birn, C. (Eds.), *INF-DH-2018*. Bonn: Gesellschaft für Informatik e.V.. DOI: 10.18420/infdh2018-16.\n",
    "\n",
    "Sprugnoli, R., Passarotti, M., Corbetta, D. & Peverelli, A. (2020). Odi et Amo. Creating, Evaluating and Extending Sentiment Lexicons for Latin. In *Proceedings of the 12th Language Resources and Evaluation Conference*, 3078-3086.\n",
    "\n",
    "Völkl, Y. (2022). Spectatoriale Geschlechterkonstruktionen. Geschlechtsspezifische Wissens- und Welterzeugung in den französisch- und spanischsprachigen Moralischen Wochenschriften des 18. Jahrhunderts, Bielefeld, transcript. DOI: 10.14361/9783839461037\n",
    "\n",
    "Zehe, A., Becker, M., Jannidis, F. & Hotho, A. (2017). Towards Sentiment Analysis on German Literature. 387-394. DOI: 10.1007/978-3-319-67190-1_36.\n",
    "\n",
    "Zhang, L., Wang, S., & Liu, B. (2018). Deep learning for sentiment analysis: A survey. In *Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery*, 8(4), e1253."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
